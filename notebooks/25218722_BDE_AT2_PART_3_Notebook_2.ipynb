{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb9ea948-2ffd-43e8-94bf-945a24873000",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# PART - 3\n",
    "---------\n",
    "## Model - 2 (PassiveAggressiveRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58285f8c-17e9-47ea-8375-feb8268da086",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import warnings to ignore UserWarnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0684e9cf-5c59-4c19-a8b9-b0129219f1fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model and preprocessor loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Use the Preprocessor that is already saved\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "save_path = \"/Volumes/workspace/bde/assignment2\"\n",
    "\n",
    "# Ensure directory exists\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# Load preprocessor\n",
    "preprocessor = joblib.load(os.path.join(save_path, \"preprocessor.joblib\"))\n",
    "\n",
    "print(\"✅ Model and preprocessor loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e5264a2-d61f-478f-996f-4616f4d42bcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 25689161\nTraining in 129 batches of up to 200000 rows.\n✅ Batch trained: 200000 rows, Time: 14.77s, Total rows processed: 200000\n✅ Batch trained: 200000 rows, Time: 14.94s, Total rows processed: 400000\n✅ Batch trained: 200000 rows, Time: 14.90s, Total rows processed: 600000\n✅ Batch trained: 200000 rows, Time: 14.55s, Total rows processed: 800000\n✅ Batch trained: 200000 rows, Time: 15.01s, Total rows processed: 1000000\n✅ Batch trained: 200000 rows, Time: 15.03s, Total rows processed: 1200000\n✅ Batch trained: 200000 rows, Time: 15.19s, Total rows processed: 1400000\n✅ Batch trained: 200000 rows, Time: 14.85s, Total rows processed: 1600000\n✅ Batch trained: 200000 rows, Time: 14.74s, Total rows processed: 1800000\n✅ Batch trained: 200000 rows, Time: 15.02s, Total rows processed: 2000000\n✅ Batch trained: 200000 rows, Time: 14.67s, Total rows processed: 2200000\n✅ Batch trained: 200000 rows, Time: 14.74s, Total rows processed: 2400000\n✅ Batch trained: 200000 rows, Time: 14.73s, Total rows processed: 2600000\n✅ Batch trained: 200000 rows, Time: 14.70s, Total rows processed: 2800000\n✅ Batch trained: 200000 rows, Time: 15.06s, Total rows processed: 3000000\n✅ Batch trained: 200000 rows, Time: 15.08s, Total rows processed: 3200000\n✅ Batch trained: 200000 rows, Time: 14.87s, Total rows processed: 3400000\n✅ Batch trained: 200000 rows, Time: 15.25s, Total rows processed: 3600000\n✅ Batch trained: 200000 rows, Time: 14.96s, Total rows processed: 3800000\n✅ Batch trained: 200000 rows, Time: 14.77s, Total rows processed: 4000000\n✅ Batch trained: 200000 rows, Time: 14.91s, Total rows processed: 4200000\n✅ Batch trained: 200000 rows, Time: 15.25s, Total rows processed: 4400000\n✅ Batch trained: 200000 rows, Time: 15.29s, Total rows processed: 4600000\n✅ Batch trained: 200000 rows, Time: 15.13s, Total rows processed: 4800000\n✅ Batch trained: 200000 rows, Time: 14.74s, Total rows processed: 5000000\n✅ Batch trained: 200000 rows, Time: 14.97s, Total rows processed: 5200000\n✅ Batch trained: 200000 rows, Time: 14.40s, Total rows processed: 5400000\n✅ Batch trained: 200000 rows, Time: 15.14s, Total rows processed: 5600000\n✅ Batch trained: 200000 rows, Time: 14.99s, Total rows processed: 5800000\n✅ Batch trained: 200000 rows, Time: 15.02s, Total rows processed: 6000000\n✅ Batch trained: 200000 rows, Time: 14.80s, Total rows processed: 6200000\n✅ Batch trained: 200000 rows, Time: 14.87s, Total rows processed: 6400000\n✅ Batch trained: 200000 rows, Time: 15.00s, Total rows processed: 6600000\n✅ Batch trained: 200000 rows, Time: 15.06s, Total rows processed: 6800000\n✅ Batch trained: 200000 rows, Time: 15.05s, Total rows processed: 7000000\n✅ Batch trained: 200000 rows, Time: 15.19s, Total rows processed: 7200000\n✅ Batch trained: 200000 rows, Time: 14.79s, Total rows processed: 7400000\n✅ Batch trained: 200000 rows, Time: 14.96s, Total rows processed: 7600000\n✅ Batch trained: 200000 rows, Time: 14.66s, Total rows processed: 7800000\n✅ Batch trained: 200000 rows, Time: 14.93s, Total rows processed: 8000000\n✅ Batch trained: 200000 rows, Time: 14.86s, Total rows processed: 8200000\n✅ Batch trained: 200000 rows, Time: 14.63s, Total rows processed: 8400000\n✅ Batch trained: 200000 rows, Time: 14.78s, Total rows processed: 8600000\n✅ Batch trained: 200000 rows, Time: 14.87s, Total rows processed: 8800000\n✅ Batch trained: 200000 rows, Time: 14.64s, Total rows processed: 9000000\n✅ Batch trained: 200000 rows, Time: 17.73s, Total rows processed: 9200000\n✅ Batch trained: 200000 rows, Time: 15.05s, Total rows processed: 9400000\n✅ Batch trained: 200000 rows, Time: 14.30s, Total rows processed: 9600000\n✅ Batch trained: 200000 rows, Time: 14.87s, Total rows processed: 9800000\n✅ Batch trained: 200000 rows, Time: 15.06s, Total rows processed: 10000000\n✅ Batch trained: 200000 rows, Time: 15.13s, Total rows processed: 10200000\n✅ Batch trained: 200000 rows, Time: 15.13s, Total rows processed: 10400000\n✅ Batch trained: 200000 rows, Time: 14.82s, Total rows processed: 10600000\n✅ Batch trained: 200000 rows, Time: 14.99s, Total rows processed: 10800000\n✅ Batch trained: 200000 rows, Time: 14.80s, Total rows processed: 11000000\n✅ Batch trained: 200000 rows, Time: 14.98s, Total rows processed: 11200000\n✅ Batch trained: 200000 rows, Time: 14.61s, Total rows processed: 11400000\n✅ Batch trained: 200000 rows, Time: 15.25s, Total rows processed: 11600000\n✅ Batch trained: 200000 rows, Time: 14.85s, Total rows processed: 11800000\n✅ Batch trained: 200000 rows, Time: 14.72s, Total rows processed: 12000000\n✅ Batch trained: 200000 rows, Time: 14.79s, Total rows processed: 12200000\n✅ Batch trained: 200000 rows, Time: 14.89s, Total rows processed: 12400000\n✅ Batch trained: 200000 rows, Time: 14.76s, Total rows processed: 12600000\n✅ Batch trained: 200000 rows, Time: 15.51s, Total rows processed: 12800000\n✅ Batch trained: 200000 rows, Time: 14.89s, Total rows processed: 13000000\n✅ Batch trained: 200000 rows, Time: 14.77s, Total rows processed: 13200000\n✅ Batch trained: 200000 rows, Time: 14.74s, Total rows processed: 13400000\n✅ Batch trained: 200000 rows, Time: 15.41s, Total rows processed: 13600000\n✅ Batch trained: 200000 rows, Time: 14.91s, Total rows processed: 13800000\n✅ Batch trained: 200000 rows, Time: 14.64s, Total rows processed: 14000000\n✅ Batch trained: 200000 rows, Time: 14.83s, Total rows processed: 14200000\n✅ Batch trained: 200000 rows, Time: 14.70s, Total rows processed: 14400000\n✅ Batch trained: 200000 rows, Time: 14.97s, Total rows processed: 14600000\n✅ Batch trained: 200000 rows, Time: 14.90s, Total rows processed: 14800000\n✅ Batch trained: 200000 rows, Time: 14.71s, Total rows processed: 15000000\n✅ Batch trained: 200000 rows, Time: 15.10s, Total rows processed: 15200000\n✅ Batch trained: 200000 rows, Time: 14.79s, Total rows processed: 15400000\n✅ Batch trained: 200000 rows, Time: 14.96s, Total rows processed: 15600000\n✅ Batch trained: 200000 rows, Time: 14.83s, Total rows processed: 15800000\n✅ Batch trained: 200000 rows, Time: 14.93s, Total rows processed: 16000000\n✅ Batch trained: 200000 rows, Time: 14.83s, Total rows processed: 16200000\n✅ Batch trained: 200000 rows, Time: 15.00s, Total rows processed: 16400000\n✅ Batch trained: 200000 rows, Time: 15.45s, Total rows processed: 16600000\n✅ Batch trained: 200000 rows, Time: 15.36s, Total rows processed: 16800000\n✅ Batch trained: 200000 rows, Time: 14.84s, Total rows processed: 17000000\n✅ Batch trained: 200000 rows, Time: 14.67s, Total rows processed: 17200000\n✅ Batch trained: 200000 rows, Time: 14.54s, Total rows processed: 17400000\n✅ Batch trained: 200000 rows, Time: 14.57s, Total rows processed: 17600000\n✅ Batch trained: 200000 rows, Time: 14.38s, Total rows processed: 17800000\n✅ Batch trained: 200000 rows, Time: 15.14s, Total rows processed: 18000000\n✅ Batch trained: 200000 rows, Time: 14.90s, Total rows processed: 18200000\n✅ Batch trained: 200000 rows, Time: 15.03s, Total rows processed: 18400000\n✅ Batch trained: 200000 rows, Time: 15.16s, Total rows processed: 18600000\n✅ Batch trained: 200000 rows, Time: 14.87s, Total rows processed: 18800000\n✅ Batch trained: 200000 rows, Time: 14.96s, Total rows processed: 19000000\n✅ Batch trained: 200000 rows, Time: 14.91s, Total rows processed: 19200000\n✅ Batch trained: 200000 rows, Time: 14.86s, Total rows processed: 19400000\n✅ Batch trained: 200000 rows, Time: 14.97s, Total rows processed: 19600000\n✅ Batch trained: 200000 rows, Time: 14.93s, Total rows processed: 19800000\n✅ Batch trained: 200000 rows, Time: 14.74s, Total rows processed: 20000000\n✅ Batch trained: 200000 rows, Time: 14.27s, Total rows processed: 20200000\n✅ Batch trained: 200000 rows, Time: 15.03s, Total rows processed: 20400000\n✅ Batch trained: 200000 rows, Time: 14.99s, Total rows processed: 20600000\n✅ Batch trained: 200000 rows, Time: 15.04s, Total rows processed: 20800000\n✅ Batch trained: 200000 rows, Time: 14.99s, Total rows processed: 21000000\n✅ Batch trained: 200000 rows, Time: 15.35s, Total rows processed: 21200000\n✅ Batch trained: 200000 rows, Time: 15.24s, Total rows processed: 21400000\n✅ Batch trained: 200000 rows, Time: 15.75s, Total rows processed: 21600000\n✅ Batch trained: 200000 rows, Time: 15.02s, Total rows processed: 21800000\n✅ Batch trained: 200000 rows, Time: 14.76s, Total rows processed: 22000000\n✅ Batch trained: 200000 rows, Time: 14.83s, Total rows processed: 22200000\n✅ Batch trained: 200000 rows, Time: 15.11s, Total rows processed: 22400000\n✅ Batch trained: 200000 rows, Time: 14.61s, Total rows processed: 22600000\n✅ Batch trained: 200000 rows, Time: 14.61s, Total rows processed: 22800000\n✅ Batch trained: 200000 rows, Time: 15.57s, Total rows processed: 23000000\n✅ Batch trained: 200000 rows, Time: 14.90s, Total rows processed: 23200000\n✅ Batch trained: 200000 rows, Time: 15.04s, Total rows processed: 23400000\n✅ Batch trained: 200000 rows, Time: 14.73s, Total rows processed: 23600000\n✅ Batch trained: 200000 rows, Time: 15.02s, Total rows processed: 23800000\n✅ Batch trained: 200000 rows, Time: 14.78s, Total rows processed: 24000000\n✅ Batch trained: 200000 rows, Time: 14.93s, Total rows processed: 24200000\n✅ Batch trained: 200000 rows, Time: 15.05s, Total rows processed: 24400000\n✅ Batch trained: 200000 rows, Time: 15.37s, Total rows processed: 24600000\n✅ Batch trained: 200000 rows, Time: 15.19s, Total rows processed: 24800000\n✅ Batch trained: 200000 rows, Time: 15.16s, Total rows processed: 25000000\n✅ Batch trained: 200000 rows, Time: 14.89s, Total rows processed: 25200000\n✅ Batch trained: 200000 rows, Time: 15.10s, Total rows processed: 25400000\n✅ Batch trained: 200000 rows, Time: 14.88s, Total rows processed: 25600000\n✅ Batch trained: 89161 rows, Time: 14.00s, Total rows processed: 25689161\n\uD83C\uDF89 Model trained on full dataset using partial_fit.\n"
     ]
    }
   ],
   "source": [
    "# Import Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import functions as F\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline as sk_pipeline\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "# Set up dataset and columns\n",
    "df = spark.table(\"train_df_2024_delta\")  # PySpark DataFrame with 25+ million rows\n",
    "\n",
    "# Categorical and numerical columns\n",
    "categorical_cols = [\"pickup_borough\", \"dropoff_borough\", \"RatecodeID\", \"payment_type\", \"trip_type\", \"taxi_colour\"]\n",
    "numerical_cols = [\n",
    "    \"passenger_count\", \"trip_distance\", \"trip_time\", \"speed_mph\", \"extra\", \"mta_tax\",\n",
    "    \"tip_amount\", \"ehail_fee\", \"improvement_surcharge\", \"congestion_surcharge\", \"airport_fee\",\n",
    "    \"month\", \"day_of_week\", \"hour\"\n",
    "]\n",
    "target_col = \"total_amount\"\n",
    "all_cols_for_preprocessor = categorical_cols + numerical_cols\n",
    "\n",
    "# Initialize SGDRegressor for partial_fit\n",
    "model = PassiveAggressiveRegressor()\n",
    "\n",
    "BATCH_SIZE = 200_000\n",
    "offset = 0\n",
    "total_rows = df.count()\n",
    "num_batches = int(np.ceil(total_rows / BATCH_SIZE))\n",
    "\n",
    "print(f\"Total rows: {total_rows}\")\n",
    "print(f\"Training in {num_batches} batches of up to {BATCH_SIZE} rows.\")\n",
    "\n",
    "# Batch-wise training\n",
    "while offset < total_rows:\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Use Spark SQL row_number for batching (avoid limit/offset issues)\n",
    "    batch_df = spark.sql(f\"\"\"\n",
    "        SELECT *\n",
    "        FROM (\n",
    "            SELECT *, ROW_NUMBER() OVER (ORDER BY total_amount) AS rn\n",
    "            FROM train_df_2024_delta\n",
    "        ) tmp\n",
    "        WHERE rn > {offset} AND rn <= {offset + BATCH_SIZE}\n",
    "    \"\"\")\n",
    "\n",
    "    batch_pandas_df = batch_df.toPandas()\n",
    "    if batch_pandas_df.empty:\n",
    "        break\n",
    "\n",
    "    # Split features and target\n",
    "    X_batch = batch_pandas_df[all_cols_for_preprocessor]\n",
    "    y_batch = batch_pandas_df[target_col]\n",
    "\n",
    "    # Preprocess\n",
    "    X_batch_processed = preprocessor.transform(X_batch)\n",
    "\n",
    "    # Partial fit\n",
    "    model.partial_fit(X_batch_processed, y_batch)\n",
    "\n",
    "    offset += len(X_batch)\n",
    "    end_time = time.time()\n",
    "    print(f\"✅ Batch trained: {len(X_batch)} rows, Time: {end_time - start_time:.2f}s, Total rows processed: {offset}\")\n",
    "\n",
    "print(\"\uD83C\uDF89 Model trained on full dataset using partial_fit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "636fc731-60d0-4ddf-a1f4-929c9e8e5bf4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model and preprocessor saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save preprocessor and model\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Define the path\n",
    "save_path = \"/Volumes/workspace/bde/assignment2\"\n",
    "\n",
    "# Ensure directory exists\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# Save them\n",
    "joblib.dump(model, os.path.join(save_path, \"passive_aggressive_model.joblib\"))\n",
    "joblib.dump(preprocessor, os.path.join(save_path, \"preprocessor.joblib\"))\n",
    "\n",
    "print(\"✅ Model and preprocessor saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37cdc9ae-1515-4f70-86ca-fcb52ca95ace",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Reloaded preprocessed test set\n"
     ]
    }
   ],
   "source": [
    "# Due to long running time sometimes it shows there is no packages imported\n",
    "# So for safer side import numpy and os again\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "save_path = \"/Volumes/workspace/bde/assignment2\"\n",
    "\n",
    "X_test = np.load(os.path.join(save_path, \"X_test_processed.npy\"))\n",
    "y_test = np.load(os.path.join(save_path, \"y_test.npy\"))\n",
    "\n",
    "print(\"✅ Reloaded preprocessed test set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21699f0e-fe07-46d3-9b8e-37f12b58967d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 72.73\n"
     ]
    }
   ],
   "source": [
    "# Calculate RMSE for Test Set\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "y_pred = model.predict(X_test)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(f\"RMSE: {rmse:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "numpy",
     "scikit-learn",
     "threadpoolctl==3.2.0"
    ],
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "BDE_AT2_PART_3_Model_2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}